<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>MemoryRecords.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">v3io-kafka-client</a> &gt; <a href="index.source.html" class="el_package">org.apache.kafka.common.record</a> &gt; <span class="el_source">MemoryRecords.java</span></div><h1>MemoryRecords.java</h1><pre class="source lang-java linenums">/**
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE
 * file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file
 * to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the
 * License. You may obtain a copy of the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
 * an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
 * specific language governing permissions and limitations under the License.
 */
package org.apache.kafka.common.record;

import java.io.DataInputStream;
import java.io.EOFException;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayDeque;
import java.util.Iterator;

import org.apache.kafka.common.KafkaException;
import org.apache.kafka.common.utils.AbstractIterator;
import org.apache.kafka.common.utils.Utils;

/**
 * A {@link Records} implementation backed by a ByteBuffer.
 */
public class MemoryRecords implements Records {

    private final static int WRITE_LIMIT_FOR_READABLE_ONLY = -1;

    // the compressor used for appends-only
    private final Compressor compressor;

    // the write limit for writable buffer, which may be smaller than the buffer capacity
    private final int writeLimit;

    // the capacity of the initial buffer, which is only used for de-allocation of writable records
    private final int initialCapacity;

    // the underlying buffer used for read; while the records are still writable it is null
    private ByteBuffer buffer;

    // indicate if the memory records is writable or not (i.e. used for appends or read-only)
    private boolean writable;

    // Construct a writable memory records
<span class="nc" id="L49">    private MemoryRecords(ByteBuffer buffer, CompressionType type, boolean writable, int writeLimit) {</span>
<span class="nc" id="L50">        this.writable = writable;</span>
<span class="nc" id="L51">        this.writeLimit = writeLimit;</span>
<span class="nc" id="L52">        this.initialCapacity = buffer.capacity();</span>
<span class="nc bnc" id="L53" title="All 2 branches missed.">        if (this.writable) {</span>
<span class="nc" id="L54">            this.buffer = null;</span>
<span class="nc" id="L55">            this.compressor = new Compressor(buffer, type);</span>
        } else {
<span class="nc" id="L57">            this.buffer = buffer;</span>
<span class="nc" id="L58">            this.compressor = null;</span>
        }
<span class="nc" id="L60">    }</span>

    public static MemoryRecords emptyRecords(ByteBuffer buffer, CompressionType type, int writeLimit) {
<span class="nc" id="L63">        return new MemoryRecords(buffer, type, true, writeLimit);</span>
    }

    public static MemoryRecords emptyRecords(ByteBuffer buffer, CompressionType type) {
        // use the buffer capacity as the default write limit
<span class="nc" id="L68">        return emptyRecords(buffer, type, buffer.capacity());</span>
    }

    public static MemoryRecords readableRecords(ByteBuffer buffer) {
<span class="nc" id="L72">        return new MemoryRecords(buffer, CompressionType.NONE, false, WRITE_LIMIT_FOR_READABLE_ONLY);</span>
    }

    /**
     * Append the given record and offset to the buffer
     */
    public void append(long offset, Record record) {
<span class="nc bnc" id="L79" title="All 2 branches missed.">        if (!writable)</span>
<span class="nc" id="L80">            throw new IllegalStateException(&quot;Memory records is not writable&quot;);</span>

<span class="nc" id="L82">        int size = record.size();</span>
<span class="nc" id="L83">        compressor.putLong(offset);</span>
<span class="nc" id="L84">        compressor.putInt(size);</span>
<span class="nc" id="L85">        compressor.put(record.buffer());</span>
<span class="nc" id="L86">        compressor.recordWritten(size + Records.LOG_OVERHEAD);</span>
<span class="nc" id="L87">        record.buffer().rewind();</span>
<span class="nc" id="L88">    }</span>

    /**
     * Append a new record and offset to the buffer
     * @return crc of the record
     */
    public long append(long offset, long timestamp, byte[] key, byte[] value) {
<span class="nc bnc" id="L95" title="All 2 branches missed.">        if (!writable)</span>
<span class="nc" id="L96">            throw new IllegalStateException(&quot;Memory records is not writable&quot;);</span>

<span class="nc" id="L98">        int size = Record.recordSize(key, value);</span>
<span class="nc" id="L99">        compressor.putLong(offset);</span>
<span class="nc" id="L100">        compressor.putInt(size);</span>
<span class="nc" id="L101">        long crc = compressor.putRecord(timestamp, key, value);</span>
<span class="nc" id="L102">        compressor.recordWritten(size + Records.LOG_OVERHEAD);</span>
<span class="nc" id="L103">        return crc;</span>
    }

    /**
     * Check if we have room for a new record containing the given key/value pair
     *
     * Note that the return value is based on the estimate of the bytes written to the compressor, which may not be
     * accurate if compression is really used. When this happens, the following append may cause dynamic buffer
     * re-allocation in the underlying byte buffer stream.
     *
     * There is an exceptional case when appending a single message whose size is larger than the batch size, the
     * capacity will be the message size which is larger than the write limit, i.e. the batch size. In this case
     * the checking should be based on the capacity of the initialized buffer rather than the write limit in order
     * to accept this single record.
     */
    public boolean hasRoomFor(byte[] key, byte[] value) {
<span class="nc bnc" id="L119" title="All 2 branches missed.">        if (!this.writable)</span>
<span class="nc" id="L120">            return false;</span>

<span class="nc bnc" id="L122" title="All 2 branches missed.">        return this.compressor.numRecordsWritten() == 0 ?</span>
<span class="nc bnc" id="L123" title="All 2 branches missed.">            this.initialCapacity &gt;= Records.LOG_OVERHEAD + Record.recordSize(key, value) :</span>
<span class="nc bnc" id="L124" title="All 2 branches missed.">            this.writeLimit &gt;= this.compressor.estimatedBytesWritten() + Records.LOG_OVERHEAD + Record.recordSize(key, value);</span>
    }

    public boolean isFull() {
<span class="nc bnc" id="L128" title="All 4 branches missed.">        return !this.writable || this.writeLimit &lt;= this.compressor.estimatedBytesWritten();</span>
    }

    /**
     * Close this batch for no more appends
     */
    public void close() {
<span class="nc bnc" id="L135" title="All 2 branches missed.">        if (writable) {</span>
            // close the compressor to fill-in wrapper message metadata if necessary
<span class="nc" id="L137">            compressor.close();</span>

            // flip the underlying buffer to be ready for reads
<span class="nc" id="L140">            buffer = compressor.buffer();</span>
<span class="nc" id="L141">            buffer.flip();</span>

            // reset the writable flag
<span class="nc" id="L144">            writable = false;</span>
        }
<span class="nc" id="L146">    }</span>

    /**
     * The size of this record set
     */
    public int sizeInBytes() {
<span class="nc bnc" id="L152" title="All 2 branches missed.">        if (writable) {</span>
<span class="nc" id="L153">            return compressor.buffer().position();</span>
        } else {
<span class="nc" id="L155">            return buffer.limit();</span>
        }
    }

    /**
     * The compression rate of this record set
     */
    public double compressionRate() {
<span class="nc bnc" id="L163" title="All 2 branches missed.">        if (compressor == null)</span>
<span class="nc" id="L164">            return 1.0;</span>
        else
<span class="nc" id="L166">            return compressor.compressionRate();</span>
    }

    /**
     * Return the capacity of the initial buffer, for writable records
     * it may be different from the current buffer's capacity
     */
    public int initialCapacity() {
<span class="nc" id="L174">        return this.initialCapacity;</span>
    }

    /**
     * Get the byte buffer that backs this records instance for reading
     */
    public ByteBuffer buffer() {
<span class="nc bnc" id="L181" title="All 2 branches missed.">        if (writable)</span>
<span class="nc" id="L182">            throw new IllegalStateException(&quot;The memory records must not be writable any more before getting its underlying buffer&quot;);</span>

<span class="nc" id="L184">        return buffer.duplicate();</span>
    }

    @Override
    public Iterator&lt;LogEntry&gt; iterator() {
<span class="nc bnc" id="L189" title="All 2 branches missed.">        if (writable) {</span>
            // flip on a duplicate buffer for reading
<span class="nc" id="L191">            return new RecordsIterator((ByteBuffer) this.buffer.duplicate().flip(), false);</span>
        } else {
            // do not need to flip for non-writable buffer
<span class="nc" id="L194">            return new RecordsIterator(this.buffer.duplicate(), false);</span>
        }
    }
    
    @Override
    public String toString() {
<span class="nc" id="L200">        Iterator&lt;LogEntry&gt; iter = iterator();</span>
<span class="nc" id="L201">        StringBuilder builder = new StringBuilder();</span>
<span class="nc" id="L202">        builder.append('[');</span>
<span class="nc bnc" id="L203" title="All 2 branches missed.">        while (iter.hasNext()) {</span>
<span class="nc" id="L204">            LogEntry entry = iter.next();</span>
<span class="nc" id="L205">            builder.append('(');</span>
<span class="nc" id="L206">            builder.append(&quot;offset=&quot;);</span>
<span class="nc" id="L207">            builder.append(entry.offset());</span>
<span class="nc" id="L208">            builder.append(&quot;,&quot;);</span>
<span class="nc" id="L209">            builder.append(&quot;record=&quot;);</span>
<span class="nc" id="L210">            builder.append(entry.record());</span>
<span class="nc" id="L211">            builder.append(&quot;)&quot;);</span>
<span class="nc" id="L212">        }</span>
<span class="nc" id="L213">        builder.append(']');</span>
<span class="nc" id="L214">        return builder.toString();</span>
    }

    /** Visible for testing */
    public boolean isWritable() {
<span class="nc" id="L219">        return writable;</span>
    }

    public static class RecordsIterator extends AbstractIterator&lt;LogEntry&gt; {
        private final ByteBuffer buffer;
        private final DataInputStream stream;
        private final CompressionType type;
        private final boolean shallow;
        private RecordsIterator innerIter;

        // The variables for inner iterator
        private final ArrayDeque&lt;LogEntry&gt; logEntries;
        private final long absoluteBaseOffset;

<span class="nc" id="L233">        public RecordsIterator(ByteBuffer buffer, boolean shallow) {</span>
<span class="nc" id="L234">            this.type = CompressionType.NONE;</span>
<span class="nc" id="L235">            this.buffer = buffer;</span>
<span class="nc" id="L236">            this.shallow = shallow;</span>
<span class="nc" id="L237">            this.stream = new DataInputStream(new ByteBufferInputStream(buffer));</span>
<span class="nc" id="L238">            this.logEntries = null;</span>
<span class="nc" id="L239">            this.absoluteBaseOffset = -1;</span>
<span class="nc" id="L240">        }</span>

        // Private constructor for inner iterator.
<span class="nc" id="L243">        private RecordsIterator(LogEntry entry) {</span>
<span class="nc" id="L244">            this.type = entry.record().compressionType();</span>
<span class="nc" id="L245">            this.buffer = entry.record().value();</span>
<span class="nc" id="L246">            this.shallow = true;</span>
<span class="nc" id="L247">            this.stream = Compressor.wrapForInput(new ByteBufferInputStream(this.buffer), type, entry.record().magic());</span>
<span class="nc" id="L248">            long wrapperRecordOffset = entry.offset();</span>

<span class="nc" id="L250">            long wrapperRecordTimestamp = entry.record().timestamp();</span>
<span class="nc" id="L251">            this.logEntries = new ArrayDeque&lt;&gt;();</span>
            // If relative offset is used, we need to decompress the entire message first to compute
            // the absolute offset. For simplicity and because it's a format that is on its way out, we
            // do the same for message format version 0
            try {
                while (true) {
                    try {
<span class="nc" id="L258">                        LogEntry logEntry = getNextEntryFromStream();</span>
<span class="nc bnc" id="L259" title="All 2 branches missed.">                        if (entry.record().magic() &gt; Record.MAGIC_VALUE_V0) {</span>
<span class="nc" id="L260">                            Record recordWithTimestamp = new Record(</span>
<span class="nc" id="L261">                                    logEntry.record().buffer(),</span>
<span class="nc" id="L262">                                    wrapperRecordTimestamp,</span>
<span class="nc" id="L263">                                    entry.record().timestampType()</span>
                            );
<span class="nc" id="L265">                            logEntry = new LogEntry(logEntry.offset(), recordWithTimestamp);</span>
                        }
<span class="nc" id="L267">                        logEntries.add(logEntry);</span>
<span class="nc" id="L268">                    } catch (EOFException e) {</span>
<span class="nc" id="L269">                        break;</span>
<span class="nc" id="L270">                    }</span>
                }
<span class="nc bnc" id="L272" title="All 2 branches missed.">                if (entry.record().magic() &gt; Record.MAGIC_VALUE_V0)</span>
<span class="nc" id="L273">                    this.absoluteBaseOffset = wrapperRecordOffset - logEntries.getLast().offset();</span>
                else
<span class="nc" id="L275">                    this.absoluteBaseOffset = -1;</span>
<span class="nc" id="L276">            } catch (IOException e) {</span>
<span class="nc" id="L277">                throw new KafkaException(e);</span>
            } finally {
<span class="nc" id="L279">                Utils.closeQuietly(stream, &quot;records iterator stream&quot;);</span>
<span class="nc" id="L280">            }</span>
<span class="nc" id="L281">        }</span>

        /*
         * Read the next record from the buffer.
         * 
         * Note that in the compressed message set, each message value size is set as the size of the un-compressed
         * version of the message value, so when we do de-compression allocating an array of the specified size for
         * reading compressed value data is sufficient.
         */
        @Override
        protected LogEntry makeNext() {
<span class="nc bnc" id="L292" title="All 2 branches missed.">            if (innerDone()) {</span>
                try {
<span class="nc" id="L294">                    LogEntry entry = getNextEntry();</span>
                    // No more record to return.
<span class="nc bnc" id="L296" title="All 2 branches missed.">                    if (entry == null)</span>
<span class="nc" id="L297">                        return allDone();</span>

                    // Convert offset to absolute offset if needed.
<span class="nc bnc" id="L300" title="All 2 branches missed.">                    if (absoluteBaseOffset &gt;= 0) {</span>
<span class="nc" id="L301">                        long absoluteOffset = absoluteBaseOffset + entry.offset();</span>
<span class="nc" id="L302">                        entry = new LogEntry(absoluteOffset, entry.record());</span>
                    }

                    // decide whether to go shallow or deep iteration if it is compressed
<span class="nc" id="L306">                    CompressionType compression = entry.record().compressionType();</span>
<span class="nc bnc" id="L307" title="All 4 branches missed.">                    if (compression == CompressionType.NONE || shallow) {</span>
<span class="nc" id="L308">                        return entry;</span>
                    } else {
                        // init the inner iterator with the value payload of the message,
                        // which will de-compress the payload to a set of messages;
                        // since we assume nested compression is not allowed, the deep iterator
                        // would not try to further decompress underlying messages
                        // There will be at least one element in the inner iterator, so we don't
                        // need to call hasNext() here.
<span class="nc" id="L316">                        innerIter = new RecordsIterator(entry);</span>
<span class="nc" id="L317">                        return innerIter.next();</span>
                    }
<span class="nc" id="L319">                } catch (EOFException e) {</span>
<span class="nc" id="L320">                    return allDone();</span>
<span class="nc" id="L321">                } catch (IOException e) {</span>
<span class="nc" id="L322">                    throw new KafkaException(e);</span>
                }
            } else {
<span class="nc" id="L325">                return innerIter.next();</span>
            }
        }

        private LogEntry getNextEntry() throws IOException {
<span class="nc bnc" id="L330" title="All 2 branches missed.">            if (logEntries != null)</span>
<span class="nc" id="L331">                return getNextEntryFromEntryList();</span>
            else
<span class="nc" id="L333">                return getNextEntryFromStream();</span>
        }

        private LogEntry getNextEntryFromEntryList() {
<span class="nc bnc" id="L337" title="All 2 branches missed.">            return logEntries.isEmpty() ? null : logEntries.remove();</span>
        }

        private LogEntry getNextEntryFromStream() throws IOException {
            // read the offset
<span class="nc" id="L342">            long offset = stream.readLong();</span>
            // read record size
<span class="nc" id="L344">            int size = stream.readInt();</span>
<span class="nc bnc" id="L345" title="All 2 branches missed.">            if (size &lt; 0)</span>
<span class="nc" id="L346">                throw new IllegalStateException(&quot;Record with size &quot; + size);</span>
            // read the record, if compression is used we cannot depend on size
            // and hence has to do extra copy
            ByteBuffer rec;
<span class="nc bnc" id="L350" title="All 2 branches missed.">            if (type == CompressionType.NONE) {</span>
<span class="nc" id="L351">                rec = buffer.slice();</span>
<span class="nc" id="L352">                int newPos = buffer.position() + size;</span>
<span class="nc bnc" id="L353" title="All 2 branches missed.">                if (newPos &gt; buffer.limit())</span>
<span class="nc" id="L354">                    return null;</span>
<span class="nc" id="L355">                buffer.position(newPos);</span>
<span class="nc" id="L356">                rec.limit(size);</span>
<span class="nc" id="L357">            } else {</span>
<span class="nc" id="L358">                byte[] recordBuffer = new byte[size];</span>
<span class="nc" id="L359">                stream.readFully(recordBuffer, 0, size);</span>
<span class="nc" id="L360">                rec = ByteBuffer.wrap(recordBuffer);</span>
            }
<span class="nc" id="L362">            return new LogEntry(offset, new Record(rec));</span>
        }

        private boolean innerDone() {
<span class="nc bnc" id="L366" title="All 4 branches missed.">            return innerIter == null || !innerIter.hasNext();</span>
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.6.201602180812</span></div></body></html>