<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>KafkaProducer.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">v3io-kafka-client</a> &gt; <a href="index.source.html" class="el_package">org.apache.kafka.clients.producer</a> &gt; <span class="el_source">KafkaProducer.java</span></div><h1>KafkaProducer.java</h1><pre class="source lang-java linenums">package org.apache.kafka.clients.producer;

import io.iguaz.v3io.container.*;
import io.iguaz.v3io.daemon.client.api.consts.V3ioResultCode;
import io.iguaz.v3io.fs.client.HashMethod;
import io.iguaz.v3io.kafka.KafkaPropertiesAdapter;
import io.iguaz.v3io.kafka.OperationUtils;
import io.iguaz.v3io.kafka.SendHandler;
import io.iguaz.v3io.streaming.StreamingOperations;
import io.iguaz.v3io.streaming.StreamingOperationsFactory;
import io.iguaz.v3io.streaming.client.api.Topic;
import io.iguaz.v3io.streaming.client.api.V3IOPutRecordCallback;
import org.apache.kafka.clients.producer.internals.FutureRecordMetadata;
import org.apache.kafka.clients.producer.internals.ProduceRequestResult;
import org.apache.kafka.clients.producer.internals.ProducerInterceptors;
import org.apache.kafka.common.*;
import org.apache.kafka.common.record.CompressionType;
import org.apache.kafka.common.serialization.Serializer;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import org.slf4j.LoggerFactory;
import org.slf4j.Logger;


import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;

/**
 * Created by oded on 05/10/16.
 */
public class KafkaProducer&lt;K, V&gt; implements Producer&lt;K, V&gt; {
<span class="nc" id="L38">    private static final Logger log = LoggerFactory.getLogger(KafkaProducer.class);</span>
    private String clientId;
    private final int maxRequestSize;
    private Serializer&lt;K&gt; keySerializer;
    private Serializer&lt;V&gt; valueSerializer;
    private StreamingOperations operations;
    private Container container;
    private Properties containerConfig;
    private Partitioner partitioner;
<span class="nc" id="L47">    private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);</span>
    private ProducerInterceptors&lt;K, V&gt; interceptors;
    private ProducerConfig producerConfig;
    private Cluster cluster;
    private OperationUtils operationUtils;
    private String acks;


    /**
     * A producer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings
     * are documented &lt;a href=&quot;http://kafka.apache.org/documentation.html#producerconfigs&quot;&gt;here&lt;/a&gt;. Values can be
     * either strings or Objects of the appropriate type (for example a numeric configuration would accept either the
     * string &quot;42&quot; or the integer 42).
     * @param configs   The producer configs
     *
     */
    public KafkaProducer(Map&lt;String, Object&gt; configs) {
<span class="nc" id="L64">        this(new ProducerConfig(configs), null, null);</span>
<span class="nc" id="L65">    }</span>

    /**
     * A producer is instantiated by providing a set of key-value pairs as configuration, a key and a value {@link Serializer}.
     * Valid configuration strings are documented &lt;a href=&quot;http://kafka.apache.org/documentation.html#producerconfigs&quot;&gt;here&lt;/a&gt;.
     * Values can be either strings or Objects of the appropriate type (for example a numeric configuration would accept
     * either the string &quot;42&quot; or the integer 42).
     * @param configs   The producer configs
     * @param keySerializer  The serializer for key that implements {@link Serializer}. The configure() method won't be
     *                       called in the producer when the serializer is passed in directly.
     * @param valueSerializer  The serializer for value that implements {@link Serializer}. The configure() method won't
     *                         be called in the producer when the serializer is passed in directly.
     */
    public KafkaProducer(Map&lt;String, Object&gt; configs, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer) {
<span class="nc" id="L79">        this(new ProducerConfig(ProducerConfig.addSerializerToConfig(configs, keySerializer, valueSerializer)),</span>
                keySerializer, valueSerializer);
<span class="nc" id="L81">    }</span>

    /**
     * A producer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings
     * are documented &lt;a href=&quot;http://kafka.apache.org/documentation.html#producerconfigs&quot;&gt;here&lt;/a&gt;.
     * @param properties   The producer configs
     */
    public KafkaProducer(Properties properties) {
<span class="nc" id="L89">        this(new ProducerConfig(properties), null, null);</span>
<span class="nc" id="L90">    }</span>

    /**
     * A producer is instantiated by providing a set of key-value pairs as configuration, a key and a value {@link Serializer}.
     * Valid configuration strings are documented &lt;a href=&quot;http://kafka.apache.org/documentation.html#producerconfigs&quot;&gt;here&lt;/a&gt;.
     * @param properties   The producer configs
     * @param keySerializer  The serializer for key that implements {@link Serializer}. The configure() method won't be
     *                       called in the producer when the serializer is passed in directly.
     * @param valueSerializer  The serializer for value that implements {@link Serializer}. The configure() method won't
     *                         be called in the producer when the serializer is passed in directly.
     */
    public KafkaProducer(Properties properties, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer) {
<span class="nc" id="L102">       this(new ProducerConfig(ProducerConfig.addSerializerToConfig(properties, keySerializer, valueSerializer)),</span>
                keySerializer, valueSerializer);
<span class="nc" id="L104">    }</span>

<span class="nc" id="L106">    private KafkaProducer(ProducerConfig config, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer)    {</span>
<span class="nc" id="L107">        Map&lt;String, Object&gt; userProvidedConfigs = config.originals();</span>
<span class="nc" id="L108">        this.producerConfig = config;</span>
<span class="nc" id="L109">        clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);</span>
<span class="nc bnc" id="L110" title="All 2 branches missed.">        if (clientId.length() &lt;= 0) {</span>
<span class="nc" id="L111">            clientId = &quot;producer-&quot; + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();</span>
        }
<span class="nc bnc" id="L113" title="All 2 branches missed.">        if (keySerializer == null) {</span>
<span class="nc" id="L114">            this.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,</span>
                    Serializer.class);
<span class="nc" id="L116">            this.keySerializer.configure(config.originals(), true);</span>
        } else {
<span class="nc" id="L118">            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);</span>
<span class="nc" id="L119">            this.keySerializer = keySerializer;</span>
        }
<span class="nc bnc" id="L121" title="All 2 branches missed.">        if (valueSerializer == null) {</span>
<span class="nc" id="L122">            this.valueSerializer = config.getConfiguredInstance(VALUE_SERIALIZER_CLASS_CONFIG,</span>
                    Serializer.class);
<span class="nc" id="L124">            this.valueSerializer.configure(config.originals(), false);</span>
        } else {
<span class="nc" id="L126">            config.ignore(VALUE_SERIALIZER_CLASS_CONFIG);</span>
<span class="nc" id="L127">            this.valueSerializer = valueSerializer;</span>
        }

<span class="nc" id="L130">        this.acks = config.getString(ProducerConfig.ACKS_CONFIG);</span>

        // load interceptors and make sure they get clientId
<span class="nc" id="L133">        userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);</span>
<span class="nc" id="L134">        List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) (new ProducerConfig(userProvidedConfigs)).getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,</span>
                ProducerInterceptor.class);
<span class="nc bnc" id="L136" title="All 2 branches missed.">        this.interceptors = interceptorList.isEmpty() ? null : new ProducerInterceptors&lt;&gt;(interceptorList);</span>
<span class="nc" id="L137">        this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);</span>

<span class="nc" id="L139">        this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);</span>

        /**
         * v3io objects.
         */
        try {
<span class="nc" id="L145">            this.containerConfig  = KafkaPropertiesAdapter.convert(this.producerConfig);</span>
<span class="nc" id="L146">            this.container = ContainerFactory.create(containerConfig);</span>
<span class="nc" id="L147">            this.operations = StreamingOperationsFactory.create(this.container,this.containerConfig);</span>
<span class="nc" id="L148">        } catch (IOException e) {</span>
<span class="nc" id="L149">            e.printStackTrace();</span>
<span class="nc" id="L150">            throw new RuntimeException(&quot;Cannot initializa container ...&quot;,e);</span>
<span class="nc" id="L151">        }</span>
<span class="nc" id="L152">        this.operationUtils = new OperationUtils(this.operations);</span>
<span class="nc" id="L153">        this.cluster = new Cluster(this.operationUtils);</span>




<span class="nc" id="L158">    }</span>

    @Override
    public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record)  {

<span class="nc" id="L163">        return(send(record,null));</span>
    }

    /**
     * create a message in a ByteBuffer.
     * @param key the message key.
     * @param value the message value.
     * @return ByteBuffer.
     */
    private ByteBuffer createMsg(byte key[],byte value[]) {

<span class="nc" id="L174">        int keyLen = key.length;</span>
<span class="nc" id="L175">        int valueLen = value.length;</span>
<span class="nc" id="L176">        int capacity = keyLen + valueLen + 8;</span>
<span class="nc" id="L177">        ByteBuffer bf = ByteBuffer.allocateDirect(capacity);</span>
<span class="nc" id="L178">        bf.putInt(keyLen);</span>
<span class="nc" id="L179">        bf.putInt(valueLen);</span>
<span class="nc" id="L180">        bf.put(key);</span>
<span class="nc" id="L181">        bf.put(value);</span>
<span class="nc" id="L182">        return(bf);</span>
    }

    @Override
    public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, final Callback callback)    {

<span class="nc" id="L188">        final String topic = record.topic();</span>

        // call interceptors list.
<span class="nc bnc" id="L191" title="All 2 branches missed.">        if(this.interceptors != null) {</span>
<span class="nc" id="L192">            record = this.interceptors.onSend(record);</span>
        }
        try {
<span class="nc" id="L195">            Topic t = operations.getTopic(topic);</span>

<span class="nc" id="L197">        } catch (IOException e) {</span>
<span class="nc" id="L198">            log.debug(&quot;creating topic...&quot;);</span>
            try {
<span class="nc" id="L200">                operations.createTopic(topic, (short) 1, 2, HashMethod.MD5);</span>
<span class="nc" id="L201">            } catch (IOException e1) {</span>
<span class="nc" id="L202">                e1.printStackTrace();</span>
<span class="nc" id="L203">            }</span>
            //e.printStackTrace();
<span class="nc" id="L205">        }</span>


<span class="nc" id="L208">        final byte key[] = this.keySerializer.serialize(topic,record.key());</span>
<span class="nc" id="L209">        final byte value[] = this.valueSerializer.serialize(topic,record.value());</span>
<span class="nc" id="L210">        final int partitionId = partitioner.partition(record.topic(),record.key(),key,record.value(),value,this.cluster);</span>
<span class="nc" id="L211">        final long ts = System.currentTimeMillis();</span>
<span class="nc" id="L212">        long nanoTs = System.nanoTime();</span>
<span class="nc" id="L213">        final ProduceRequestResult res = new ProduceRequestResult();</span>
<span class="nc" id="L214">        final FutureRecordMetadata futureRecordMetadata = new FutureRecordMetadata(res,1,ts,0,key.length,value.length);</span>


<span class="nc" id="L217">        final org.apache.kafka.common.TopicPartition topicPartition = new org.apache.kafka.common.TopicPartition(topic, partitionId);</span>


<span class="nc" id="L220">        io.iguaz.v3io.streaming.client.api.ProducerRecord prec =</span>
<span class="nc" id="L221">            new io.iguaz.v3io.streaming.client.api.ProducerRecord(topic,(short)partitionId,new Long(ts),key,value);</span>

<span class="nc" id="L223">        final SendHandler handler = new SendHandler(this.interceptors,callback);</span>
        try {
<span class="nc bnc" id="L225" title="All 2 branches missed.">            if (acks.equalsIgnoreCase(&quot;all&quot;)) {</span>
<span class="nc" id="L226">                log.info(&quot;Using callback since ack required.&quot;);</span>
<span class="nc" id="L227">                this.operations.putRecord(prec, new V3IOPutRecordCallback() {</span>
                    @Override
                    public void onSuccess(long sequenceId, short partitionId) {
<span class="nc" id="L230">                        RecordMetadata recordMetadata = new RecordMetadata(topicPartition, 0, sequenceId, ts, 0, key.length, value.length);</span>
<span class="nc" id="L231">                        handler.onSuccess(topicPartition, recordMetadata, res, sequenceId);</span>
<span class="nc" id="L232">                    }</span>

                    @Override
                    public void onFailure(V3ioResultCode.Errors errCode) {
<span class="nc" id="L236">                        RecordMetadata recordMetadata = new RecordMetadata(topicPartition, 0, 0, ts, 0, key.length, value.length);</span>
<span class="nc" id="L237">                        String msg = errCode.toString();</span>
<span class="nc" id="L238">                        KafkaException exception = new KafkaException(msg);</span>
<span class="nc" id="L239">                        handler.onError(topicPartition, recordMetadata, res, exception);</span>

<span class="nc" id="L241">                    }</span>
                });
            } else {
<span class="nc" id="L244">                log.info(&quot;Not using callback since not ack it required.&quot;);</span>
<span class="nc" id="L245">                RecordMetadata recordMetadata = new RecordMetadata(topicPartition, 0, 0, ts, 0, key.length, value.length);</span>
<span class="nc" id="L246">                this.operations.putRecord(prec, null);</span>
<span class="nc" id="L247">                handler.onSuccess(topicPartition, recordMetadata, res, 0);</span>
            }
<span class="nc" id="L249">        } catch (Exception e) {</span>
<span class="nc" id="L250">            RecordMetadata recordMetadata = new RecordMetadata(topicPartition, 0, 0, ts, 0, key.length, value.length);</span>
<span class="nc" id="L251">            KafkaException exception = new KafkaException(e);</span>
<span class="nc" id="L252">            handler.onError(topicPartition, recordMetadata, res, exception);</span>

<span class="nc" id="L254">        }</span>
<span class="nc" id="L255">        return(futureRecordMetadata);</span>
    }




    @Override
    public void flush() {

<span class="nc" id="L264">    }</span>

    @Override
    public List&lt;PartitionInfo&gt; partitionsFor(String topic) {

<span class="nc" id="L269">        List&lt;PartitionInfo&gt; partitions = null;</span>
        try {
<span class="nc" id="L271">            partitions =  operationUtils.getPartitionsForTopic(topic);</span>
<span class="nc" id="L272">        } catch (IOException e) {</span>
<span class="nc" id="L273">            log.error(&quot;Error getting partitions for topic: &quot; + topic,e);</span>
<span class="nc" id="L274">            partitions = null;</span>
<span class="nc" id="L275">        }</span>
<span class="nc" id="L276">        return(partitions);</span>
    }

    @Override
    public Map&lt;MetricName, ? extends Metric&gt; metrics() {
<span class="nc" id="L281">        throw new UnsupportedOperationException(&quot;Method metrics not supported.&quot;);</span>
    }

    @Override
    public void close() {

        try {
<span class="nc" id="L288">            container.close();</span>
<span class="nc" id="L289">        } catch (IOException e) {</span>
<span class="nc" id="L290">            e.printStackTrace();</span>
<span class="nc" id="L291">            log.error(&quot;Error closing container&quot;,e);</span>
<span class="nc" id="L292">        }</span>

<span class="nc" id="L294">    }</span>

    @Override
    public void close(long timeout, TimeUnit unit) {
<span class="nc" id="L298">        close();</span>

<span class="nc" id="L300">    }</span>


}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.6.201602180812</span></div></body></html>